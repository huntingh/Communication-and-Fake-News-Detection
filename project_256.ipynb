{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huntingh/ECE570-Project/blob/main/project_256.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBYjp_UYJkI7"
      },
      "source": [
        "Loading train, test and valid data from LIAR dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "94LazYcdgWpj",
        "outputId": "55d93830-e194-4e2e-92d7-2860229ed477"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1cec1166-4d42-4acd-b97b-0365f41c7cf7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1cec1166-4d42-4acd-b97b-0365f41c7cf7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.tsv to test (1).tsv\n",
            "Saving train.tsv to train (1).tsv\n",
            "Saving valid.tsv to valid (1).tsv\n"
          ]
        }
      ],
      "source": [
        "# https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dVSmhVVMJLPy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_train = pd.read_csv(\"train.tsv\", sep=\"\\t\", header=None)\n",
        "data_valid = pd.read_csv(\"valid.tsv\", sep=\"\\t\", header=None)\n",
        "data_test = pd.read_csv(\"test.tsv\", sep=\"\\t\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "3ak9AurkJsIy",
        "outputId": "b566e142-18ee-49b1-bce5-974870fe3b77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0            1                                                  2   \\\n",
              "0   2635.json        false  Says the Annies List political group supports ...   \n",
              "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
              "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
              "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
              "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
              "\n",
              "                                   3               4                     5   \\\n",
              "0                            abortion    dwayne-bohac  State representative   \n",
              "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
              "2                      foreign-policy    barack-obama             President   \n",
              "3                         health-care    blog-posting                   NaN   \n",
              "4                        economy,jobs   charlie-crist                   NaN   \n",
              "\n",
              "         6           7     8     9      10     11    12                   13  \n",
              "0     Texas  republican   0.0   1.0    0.0    0.0   0.0             a mailer  \n",
              "1  Virginia    democrat   0.0   0.0    1.0    1.0   0.0      a floor speech.  \n",
              "2  Illinois    democrat  70.0  71.0  160.0  163.0   9.0               Denver  \n",
              "3       NaN        none   7.0  19.0    3.0    5.0  44.0       a news release  \n",
              "4   Florida    democrat  15.0   9.0   20.0   19.0   2.0  an interview on CNN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07b48366-5214-48bb-aae0-045bb12a407c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2635.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says the Annies List political group supports ...</td>\n",
              "      <td>abortion</td>\n",
              "      <td>dwayne-bohac</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a mailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10540.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>When did the decline of coal start? It started...</td>\n",
              "      <td>energy,history,job-accomplishments</td>\n",
              "      <td>scott-surovell</td>\n",
              "      <td>State delegate</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>a floor speech.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>324.json</td>\n",
              "      <td>mostly-true</td>\n",
              "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
              "      <td>foreign-policy</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Denver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1123.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Health care reform legislation is likely to ma...</td>\n",
              "      <td>health-care</td>\n",
              "      <td>blog-posting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>a news release</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9028.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>The economic turnaround started at the end of ...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>charlie-crist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Florida</td>\n",
              "      <td>democrat</td>\n",
              "      <td>15.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>an interview on CNN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07b48366-5214-48bb-aae0-045bb12a407c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07b48366-5214-48bb-aae0-045bb12a407c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07b48366-5214-48bb-aae0-045bb12a407c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#Viewing sample train data before preprocessing\n",
        "data_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "6vz0R-tNJePi",
        "outputId": "81e34d9f-1df3-4ca7-b365-074af8ed784c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0           1                                                  2   \\\n",
              "0  11972.json        true  Building a wall on the U.S.-Mexico border will...   \n",
              "1  11685.json       false  Wisconsin is on pace to double the number of l...   \n",
              "2  11096.json       false  Says John McCain has done nothing to help the ...   \n",
              "3   5209.json   half-true  Suzanne Bonamici supports a plan that will cut...   \n",
              "4   9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
              "\n",
              "                                                  3   \\\n",
              "0                                        immigration   \n",
              "1                                               jobs   \n",
              "2                    military,veterans,voting-record   \n",
              "3  medicare,message-machine-2012,campaign-adverti...   \n",
              "4  campaign-finance,legal-issues,campaign-adverti...   \n",
              "\n",
              "                                 4                     5          6   \\\n",
              "0                        rick-perry              Governor      Texas   \n",
              "1                 katrina-shankland  State representative  Wisconsin   \n",
              "2                      donald-trump       President-Elect   New York   \n",
              "3                     rob-cornilles            consultant     Oregon   \n",
              "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
              "\n",
              "           7   8    9   10  11  12                            13  \n",
              "0  republican  30   30  42  23  18               Radio interview  \n",
              "1    democrat   2    1   0   0   0             a news conference  \n",
              "2  republican  63  114  51  37  61  comments on ABC's This Week.  \n",
              "3  republican   1    1   3   1   1                  a radio show  \n",
              "4    democrat   5    7   2   2   7                   a web video  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ccc1d35-6968-4225-a2ba-a9923ff5f614\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11972.json</td>\n",
              "      <td>true</td>\n",
              "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
              "      <td>immigration</td>\n",
              "      <td>rick-perry</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>Radio interview</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11685.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Wisconsin is on pace to double the number of l...</td>\n",
              "      <td>jobs</td>\n",
              "      <td>katrina-shankland</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>democrat</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a news conference</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11096.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says John McCain has done nothing to help the ...</td>\n",
              "      <td>military,veterans,voting-record</td>\n",
              "      <td>donald-trump</td>\n",
              "      <td>President-Elect</td>\n",
              "      <td>New York</td>\n",
              "      <td>republican</td>\n",
              "      <td>63</td>\n",
              "      <td>114</td>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "      <td>61</td>\n",
              "      <td>comments on ABC's This Week.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5209.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
              "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
              "      <td>rob-cornilles</td>\n",
              "      <td>consultant</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>republican</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a radio show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9524.json</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>When asked by a reporter whether hes at the ce...</td>\n",
              "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
              "      <td>state-democratic-party-wisconsin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>democrat</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>a web video</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ccc1d35-6968-4225-a2ba-a9923ff5f614')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ccc1d35-6968-4225-a2ba-a9923ff5f614 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ccc1d35-6968-4225-a2ba-a9923ff5f614');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#Viewing sample train data before preprocessing\n",
        "data_test.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "oTX7s8SIJ88V",
        "outputId": "e3f1f2b5-d31a-4bf9-d466-f1c50db9aaa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0            1                                                  2   \\\n",
              "0  12134.json  barely-true  We have less Americans working now than in the...   \n",
              "1    238.json   pants-fire  When Obama was sworn into office, he DID NOT u...   \n",
              "2   7891.json        false  Says Having organizations parading as being so...   \n",
              "3   8169.json    half-true     Says nearly half of Oregons children are poor.   \n",
              "4    929.json    half-true  On attacks by Republicans that various program...   \n",
              "\n",
              "                                 3                4   \\\n",
              "0                      economy,jobs   vicky-hartzler   \n",
              "1  obama-birth-certificate,religion      chain-email   \n",
              "2   campaign-finance,congress,taxes  earl-blumenauer   \n",
              "3                           poverty  jim-francesconi   \n",
              "4                  economy,stimulus     barack-obama   \n",
              "\n",
              "                                              5         6           7   8   \\\n",
              "0                            U.S. Representative  Missouri  republican   1   \n",
              "1                                            NaN       NaN        none  11   \n",
              "2                            U.S. representative    Oregon    democrat   0   \n",
              "3  Member of the State Board of Higher Education    Oregon        none   0   \n",
              "4                                      President  Illinois    democrat  70   \n",
              "\n",
              "   9    10   11   12                             13  \n",
              "0   0    1    0    0   an interview with ABC17 News  \n",
              "1  43    8    5  105                            NaN  \n",
              "2   1    1    1    0  a U.S. Ways and Means hearing  \n",
              "3   1    1    1    0             an opinion article  \n",
              "4  71  160  163    9        interview with CBS News  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3786d8b-d33e-4edc-a967-c2d93076ea7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12134.json</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>We have less Americans working now than in the...</td>\n",
              "      <td>economy,jobs</td>\n",
              "      <td>vicky-hartzler</td>\n",
              "      <td>U.S. Representative</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>republican</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>an interview with ABC17 News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>238.json</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
              "      <td>obama-birth-certificate,religion</td>\n",
              "      <td>chain-email</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>none</td>\n",
              "      <td>11</td>\n",
              "      <td>43</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>105</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7891.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says Having organizations parading as being so...</td>\n",
              "      <td>campaign-finance,congress,taxes</td>\n",
              "      <td>earl-blumenauer</td>\n",
              "      <td>U.S. representative</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>democrat</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>a U.S. Ways and Means hearing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8169.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>Says nearly half of Oregons children are poor.</td>\n",
              "      <td>poverty</td>\n",
              "      <td>jim-francesconi</td>\n",
              "      <td>Member of the State Board of Higher Education</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>an opinion article</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>929.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>On attacks by Republicans that various program...</td>\n",
              "      <td>economy,stimulus</td>\n",
              "      <td>barack-obama</td>\n",
              "      <td>President</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>democrat</td>\n",
              "      <td>70</td>\n",
              "      <td>71</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>9</td>\n",
              "      <td>interview with CBS News</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3786d8b-d33e-4edc-a967-c2d93076ea7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3786d8b-d33e-4edc-a967-c2d93076ea7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3786d8b-d33e-4edc-a967-c2d93076ea7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#Viewing sample train data before preprocessing\n",
        "data_valid.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuQ5xi8FGrY_"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Mn7a_YNlKHer"
      },
      "outputs": [],
      "source": [
        "#Below function performs all the required data cleaning and preprocessing steps\n",
        "\n",
        "def data_preprocessing(dataset):\n",
        "  #Creating new column called 'label' with 1 for true and mostly-true values, else 0 i.e. 1=real, 0=fake\n",
        "  dataset['label']=[1 if x==\"true\"or x==\"mostly-true\" else 0 for x in dataset[1]] \n",
        "  #Dropping unwanted columns\n",
        "  dataset = dataset.drop(labels=[0,1,8,9,10,11,12] ,axis=1)\n",
        "  #Dealing with empty datapoints for metadata columns - subject, speaker, job, state,affiliation, context\n",
        "  meta = []\n",
        "  for i in range(len(dataset)):\n",
        "      subject = dataset[3][i]\n",
        "      if subject == 0:\n",
        "          subject = 'None'\n",
        "\n",
        "      speaker =  dataset[4][i]\n",
        "      if speaker == 0:\n",
        "          speaker = 'None'\n",
        "\n",
        "      job =  dataset[5][i]\n",
        "      if job == 0:\n",
        "          job = 'None'\n",
        "\n",
        "      state =  dataset[6][i]\n",
        "      if state == 0:\n",
        "          state = 'None'\n",
        "\n",
        "      affiliation =  dataset[7][i]\n",
        "      if affiliation == 0:\n",
        "          affiliation = 'None'\n",
        "\n",
        "      context =  dataset[13][i]\n",
        "      if context == 0 :\n",
        "          context = 'None'\n",
        "\n",
        "      meta.append(str(subject) + ' ' + str(speaker) + ' ' + str(job) + ' ' + str(state) + ' ' + str(affiliation) + ' ' + str(context)) #combining all the meta data columns into a single column\n",
        "  \n",
        "  #Adding cleaned and combined metadata column to the dataset\n",
        "  dataset[14] = meta\n",
        "  dataset[\"sentence\"] = dataset[14].astype('str')+\" \"+dataset[2] #Combining metadata and the text columns into single columns\n",
        "\n",
        "  dataset = dataset.drop([2,3,4,5,6,7,13,14], axis=1) #dropping metadata columns, as we have merged them into a single column\n",
        "  dataset.dropna() #Dropping if there are still any null values\n",
        "\n",
        "  return dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AZK3b_XYL2IW"
      },
      "outputs": [],
      "source": [
        "#Applying pre-processing to the raw data - train, valid and test sets\n",
        "data_train = data_preprocessing(data_train)\n",
        "data_valid = data_preprocessing(data_valid)\n",
        "data_test = data_preprocessing(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vVZUSRrLNU0Q",
        "outputId": "9bae6239-f562-4811-a9d4-8b28fe65186c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                           sentence\n",
              "0      0  abortion dwayne-bohac State representative Tex...\n",
              "1      0  energy,history,job-accomplishments scott-surov...\n",
              "2      1  foreign-policy barack-obama President Illinois...\n",
              "3      0  health-care blog-posting nan nan none a news r...\n",
              "4      0  economy,jobs charlie-crist nan Florida democra..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1523a21f-1e3a-44c3-b71c-c37a4d3e073a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>abortion dwayne-bohac State representative Tex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>energy,history,job-accomplishments scott-surov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>foreign-policy barack-obama President Illinois...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>health-care blog-posting nan nan none a news r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>economy,jobs charlie-crist nan Florida democra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1523a21f-1e3a-44c3-b71c-c37a4d3e073a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1523a21f-1e3a-44c3-b71c-c37a4d3e073a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1523a21f-1e3a-44c3-b71c-c37a4d3e073a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#Sample data after preprocessing\n",
        "data_train.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSZxu3GxNlEO"
      },
      "source": [
        "Analyzing the distribtuion of labels in each dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ia1xysaMLK3",
        "outputId": "9966e761-a7d5-4df4-f52d-85c2dae9f1ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6602\n",
              "1    3638\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "data_train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhDa0gwsMqb_",
        "outputId": "6839fafd-ad9d-4578-a49b-06a910369fc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    864\n",
              "1    420\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "data_valid['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGnGmf-FMqhk",
        "outputId": "2830daf2-e2af-46f4-c5e7-418cdccae5f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    818\n",
              "1    449\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "data_test['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RSiianVGvro"
      },
      "source": [
        "We can see that all the datasets have almost equal distribution of real and fake categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "jp-ADWhJMEJf",
        "outputId": "b97dd9b4-d847-482d-b7f6-673e56dd8dbb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAGbCAYAAAARGU4hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWcElEQVR4nO3dX4zd5X3n8c+3OH+qtBv+uRay2TWrWBtRaUOQRYgSrdKgAAlRzUUasepuLITkG3aVSl11nd6gJo1EbkoT7RYJBW+dKC1BtClWEjW1CFV3L0IwhZIAiXApCFuA3Rhos1FTkX73Yh4nU2rvjMk8M+PR6yWNzu/3/J5z5jn6SeO3f+ecmeruAAAwz8+s9QIAADY6wQUAMJngAgCYTHABAEwmuAAAJtu01gv4/7nwwgt7+/bta70MAIAlPfTQQ3/b3ZtPdWxdB9f27dtz6NChtV4GAMCSquqZ0x3zkiIAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJNq31AuBUtu/9ylovgVN4+tbr1noJAGelZV3hqqpzq+qeqvpOVT1RVe+sqvOr6mBVPTluzxtzq6o+U1WHq+rRqrp80ePsHvOfrKrds54UAMB6styXFD+d5E+7+61J3pbkiSR7k9zX3TuS3Df2k+T9SXaMrz1Jbk+Sqjo/yS1J3pHkiiS3nIw0AICNbMngqqo3J/kPSe5Mku7+x+5+KcmuJPvHtP1Jrh/bu5J8rhd8I8m5VXVRkmuSHOzuE939YpKDSa5d0WcDALAOLecK1yVJjif5X1X1cFV9tqrelGRLdz835jyfZMvY3prk2UX3PzLGTjf+z1TVnqo6VFWHjh8/fmbPBgBgHVpOcG1KcnmS27v77Un+b37y8mGSpLs7Sa/Egrr7ju7e2d07N2/evBIPCQCwppYTXEeSHOnuB8b+PVkIsBfGS4UZt8fG8aNJLl50/21j7HTjAAAb2pLB1d3PJ3m2qv7dGLoqyeNJDiQ5+UnD3UnuHdsHknxkfFrxyiQvj5cev5bk6qo6b7xZ/uoxBgCwoS3393D91yRfqKrXJ3kqyY1ZiLW7q+qmJM8k+fCY+9UkH0hyOMkPxtx094mq+kSSB8e8j3f3iRV5FgAA69iygqu7H0my8xSHrjrF3E5y82keZ1+SfWeyQACAs50/7QMAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEy2rOCqqqer6ltV9UhVHRpj51fVwap6ctyeN8arqj5TVYer6tGqunzR4+we85+sqt1znhIAwPpyJle4fqm7L+vunWN/b5L7untHkvvGfpK8P8mO8bUnye3JQqAluSXJO5JckeSWk5EGALCR/TQvKe5Ksn9s709y/aLxz/WCbyQ5t6ouSnJNkoPdfaK7X0xyMMm1P8X3BwA4Kyw3uDrJn1XVQ1W1Z4xt6e7nxvbzSbaM7a1Jnl103yNj7HTj/0xV7amqQ1V16Pjx48tcHgDA+rVpmfPe3d1Hq+oXkhysqu8sPtjdXVW9Egvq7juS3JEkO3fuXJHHBABYS8u6wtXdR8ftsSRfysJ7sF4YLxVm3B4b048muXjR3beNsdONAwBsaEsGV1W9qap+/uR2kquTfDvJgSQnP2m4O8m9Y/tAko+MTytemeTl8dLj15JcXVXnjTfLXz3GAAA2tOW8pLglyZeq6uT8P+juP62qB5PcXVU3JXkmyYfH/K8m+UCSw0l+kOTGJOnuE1X1iSQPjnkf7+4TK/ZMAADWqSWDq7ufSvK2U4x/L8lVpxjvJDef5rH2Jdl35ssEADh7+U3zAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZMsOrqo6p6oerqovj/1LquqBqjpcVV+sqteP8TeM/cPj+PZFj/GxMf7dqrpmpZ8MAMB6dCZXuD6a5IlF+59Kclt3vyXJi0luGuM3JXlxjN825qWqLk1yQ5JfTHJtkt+rqnN+uuUDAKx/ywquqtqW5Loknx37leS9Se4ZU/YnuX5s7xr7GcevGvN3Jbmru3/Y3X+T5HCSK1biSQAArGfLvcL1u0l+I8k/jf0LkrzU3a+M/SNJto7trUmeTZJx/OUx/8fjp7jPj1XVnqo6VFWHjh8/fgZPBQBgfVoyuKrqg0mOdfdDq7CedPcd3b2zu3du3rx5Nb4lAMBUm5Yx511JfrmqPpDkjUn+VZJPJzm3qjaNq1jbkhwd848muTjJkaralOTNSb63aPykxfcBANiwlrzC1d0f6+5t3b09C296/3p3/2qS+5N8aEzbneTesX1g7Gcc/3p39xi/YXyK8ZIkO5J8c8WeCQDAOrWcK1yn89+T3FVVv53k4SR3jvE7k3y+qg4nOZGFSEt3P1ZVdyd5PMkrSW7u7h/9FN8fAOCscEbB1d1/nuTPx/ZTOcWnDLv7H5L8ymnu/8kknzzTRQIAnM38pnkAgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZEsGV1W9saq+WVV/VVWPVdVvjfFLquqBqjpcVV+sqteP8TeM/cPj+PZFj/WxMf7dqrpm1pMCAFhPlnOF64dJ3tvdb0tyWZJrq+rKJJ9Kclt3vyXJi0luGvNvSvLiGL9tzEtVXZrkhiS/mOTaJL9XVees5JMBAFiPlgyuXvD9sfu68dVJ3pvknjG+P8n1Y3vX2M84flVV1Ri/q7t/2N1/k+RwkitW5FkAAKxjy3oPV1WdU1WPJDmW5GCSv07yUne/MqYcSbJ1bG9N8mySjOMvJ7lg8fgp7rP4e+2pqkNVdej48eNn/owAANaZZQVXd/+ouy9Lsi0LV6XeOmtB3X1Hd+/s7p2bN2+e9W0AAFbNGX1KsbtfSnJ/kncmObeqNo1D25IcHdtHk1ycJOP4m5N8b/H4Ke4DALBhLedTipur6tyx/bNJ3pfkiSyE14fGtN1J7h3bB8Z+xvGvd3eP8RvGpxgvSbIjyTdX6okAAKxXm5aekouS7B+fKPyZJHd395er6vEkd1XVbyd5OMmdY/6dST5fVYeTnMjCJxPT3Y9V1d1JHk/ySpKbu/tHK/t0AADWnyWDq7sfTfL2U4w/lVN8yrC7/yHJr5zmsT6Z5JNnvkwAgLOX3zQPADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmGzTWi8AOHts3/uVtV4Cr/L0rdet9RKAZXCFCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGRLBldVXVxV91fV41X1WFV9dIyfX1UHq+rJcXveGK+q+kxVHa6qR6vq8kWPtXvMf7Kqds97WgAA68dyrnC9kuTXu/vSJFcmubmqLk2yN8l93b0jyX1jP0nen2TH+NqT5PZkIdCS3JLkHUmuSHLLyUgDANjIlgyu7n6uu/9ybP99kieSbE2yK8n+MW1/kuvH9q4kn+sF30hyblVdlOSaJAe7+0R3v5jkYJJrV/TZAACsQ2f0Hq6q2p7k7UkeSLKlu58bh55PsmVsb03y7KK7HRljpxt/9ffYU1WHqurQ8ePHz2R5AADr0rKDq6p+LskfJfm17v67xce6u5P0Siyou+/o7p3dvXPz5s0r8ZAAAGtqWcFVVa/LQmx9obv/eAy/MF4qzLg9NsaPJrl40d23jbHTjQMAbGjL+ZRiJbkzyRPd/TuLDh1IcvKThruT3Lto/CPj04pXJnl5vPT4tSRXV9V5483yV48xAIANbdMy5rwryX9O8q2qemSM/WaSW5PcXVU3JXkmyYfHsa8m+UCSw0l+kOTGJOnuE1X1iSQPjnkf7+4TK/IsAADWsSWDq7v/T5I6zeGrTjG/k9x8msfal2TfmSwQAOBs5zfNAwBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgMsEFADCZ4AIAmExwAQBMJrgAACYTXAAAkwkuAIDJBBcAwGSCCwBgsk1rvYD1YPver6z1EgCADcwVLgCAyQQXAMBkggsAYDLBBQAwmeACAJhMcAEATCa4AAAmE1wAAJMJLgCAyQQXAMBkggsAYDLBBQAwmeACAJhMcAEATCa4AAAmE1wAAJMJLgCAyQQXAMBkggsAYDLBBQAwmeACAJhMcAEATCa4AAAmE1wAAJMJLgCAyQQXAMBkggsAYDLBBQAwmeACAJhMcAEATCa4AAAmE1wAAJMJLgCAyQQXAMBkggsAYDLBBQAw2ZLBVVX7qupYVX170dj5VXWwqp4ct+eN8aqqz1TV4ap6tKouX3Sf3WP+k1W1e87TAQBYf5Zzhev3k1z7qrG9Se7r7h1J7hv7SfL+JDvG154ktycLgZbkliTvSHJFkltORhoAwEa3ZHB1918kOfGq4V1J9o/t/UmuXzT+uV7wjSTnVtVFSa5JcrC7T3T3i0kO5l9GHADAhvRa38O1pbufG9vPJ9kytrcmeXbRvCNj7HTj/0JV7amqQ1V16Pjx469xeQAA68dP/ab57u4kvQJrOfl4d3T3zu7euXnz5pV6WACANfNag+uF8VJhxu2xMX40ycWL5m0bY6cbBwDY8F5rcB1IcvKThruT3Lto/CPj04pXJnl5vPT4tSRXV9V5483yV48xAIANb9NSE6rqD5O8J8mFVXUkC582vDXJ3VV1U5Jnknx4TP9qkg8kOZzkB0luTJLuPlFVn0jy4Jj38e5+9RvxAQA2pCWDq7v/42kOXXWKuZ3k5tM8zr4k+85odQAAG4DfNA8AMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTCS4AgMkEFwDAZIILAGAywQUAMJngAgCYTHABAEwmuAAAJhNcAACTbVrrBQDw2m3f+5W1XgKn8PSt1631ElhnXOECAJhMcAEATCa4AAAmE1wAAJMJLgCAyQQXAMBkggsAYDLBBQAwmeACAJhMcAEATCa4AAAmE1wAAJMJLgCAyVY9uKrq2qr6blUdrqq9q/39AQBW26bV/GZVdU6S/5nkfUmOJHmwqg509+OruQ4AmGn73q+s9RJ4ladvvW5Nv/9qX+G6Isnh7n6qu/8xyV1Jdq3yGgAAVtWqXuFKsjXJs4v2jyR5x+IJVbUnyZ6x+/2q+u4qrW09ujDJ3671IpjG+d3YnN+Nzfk9y9Snzmj6az2//+Z0B1Y7uJbU3XckuWOt17EeVNWh7t651utgDud3Y3N+Nzbnd2ObcX5X+yXFo0kuXrS/bYwBAGxYqx1cDybZUVWXVNXrk9yQ5MAqrwEAYFWt6kuK3f1KVf2XJF9Lck6Sfd392Gqu4SzjpdWNzfnd2Jzfjc353dhW/PxWd6/0YwIAsIjfNA8AMJngAgCYTHCtoaraV1XHqurbi8bOr6qDVfXkuD1vjFdVfWb8SaRHq+rytVs5S6mqi6vq/qp6vKoeq6qPjnHndwOoqjdW1Ter6q/G+f2tMX5JVT0wzuMXx4eDUlVvGPuHx/Hta7l+lqeqzqmqh6vqy2Pf+d0gqurpqvpWVT1SVYfG2NSfz4Jrbf1+kmtfNbY3yX3dvSPJfWM/Sd6fZMf42pPk9lVaI6/NK0l+vbsvTXJlkpur6tI4vxvFD5O8t7vfluSyJNdW1ZVJPpXktu5+S5IXk9w05t+U5MUxftuYx/r30SRPLNp3fjeWX+ruyxb9vq2pP58F1xrq7r9IcuJVw7uS7B/b+5Ncv2j8c73gG0nOraqLVmelnKnufq67/3Js/30WfmhvjfO7IYzz9P2x+7rx1Unem+SeMf7q83vyvN+T5KqqqlVaLq9BVW1Lcl2Sz479ivO70U39+Sy41p8t3f3c2H4+yZaxfao/i7R1NRfGazNeXnh7kgfi/G4Y4+WmR5IcS3IwyV8neam7XxlTFp/DH5/fcfzlJBes7oo5Q7+b5DeS/NPYvyDO70bSSf6sqh4af1Iwmfzzed39aR9+oru7qvzejrNYVf1ckj9K8mvd/XeL/9Pr/J7duvtHSS6rqnOTfCnJW9d4SayQqvpgkmPd/VBVvWet18MU7+7uo1X1C0kOVtV3Fh+c8fPZFa7154WTlyrH7bEx7s8inWWq6nVZiK0vdPcfj2Hnd4Pp7peS3J/knVl4qeHkf2QXn8Mfn99x/M1JvrfKS2X53pXkl6vq6SR3ZeGlxE/H+d0wuvvouD2Whf8wXZHJP58F1/pzIMnusb07yb2Lxj8yPi1xZZKXF136ZJ0Z79+4M8kT3f07iw45vxtAVW0eV7ZSVT+b5H1ZeJ/e/Uk+NKa9+vyePO8fSvL19lun163u/lh3b+vu7Vn4E3Rf7+5fjfO7IVTVm6rq509uJ7k6ybcz+eez3zS/hqrqD5O8J8mFSV5IckuSP0lyd5J/neSZJB/u7hPjH/D/kYVPNf4gyY3dfWgt1s3SqurdSf53km/lJ+8B+c0svI/L+T3LVdW/z8Kbas/Jwn9c7+7uj1fVv83CFZHzkzyc5D919w+r6o1JPp+F9/KdSHJDdz+1NqvnTIyXFP9bd3/Q+d0Yxnn80tjdlOQPuvuTVXVBJv58FlwAAJN5SREAYDLBBQAwmeACAJhMcAEATCa4AAAmE1wAAJMJLgCAyf4fzUeHS8aBZbYAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Analyzing length of sentences in training data to decide on MAX_LENGTH variable, which is required for BERT and RoBERTa\n",
        "\n",
        "sent_len = []\n",
        "for sent in data_train['sentence']:\n",
        "  sent_len.append(len(sent))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.boxplot(sent_len)\n",
        "plt.show()\n",
        "\n",
        "sent_len = [i for i in sent_len if i<=500] #Excluding the outliers\n",
        "fig2 = plt.figure(figsize =(10, 7))\n",
        "plt.hist(sent_len, 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBCYFJ72saCV"
      },
      "source": [
        "From the above histogram, we can see that, majority of the sentences are in the range of 150-250 and most of the sentences length is less than 350"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erVtysMsN8YB"
      },
      "source": [
        "Installing required library - transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OjfEkcAN0O1",
        "outputId": "5358729f-e84e-46ba-d745-18f8d1962f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "exw4szNhN0Rl"
      },
      "outputs": [],
      "source": [
        "#importing required packages  \n",
        "from transformers import (\n",
        "    BertForSequenceClassification,    \n",
        "    BertTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    AdamW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU742xwpN0UH",
        "outputId": "ed20562f-056b-434f-ff0c-32af707bb200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Base models loaded\n"
          ]
        }
      ],
      "source": [
        "# Loading BERT base model\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", #Using BERT base model with an uncased vocab.\n",
        "                                                                num_labels = 2, #number of output labels - 0,1 (binary classification)\n",
        "                                                                output_attentions = False, #model doesnt return attention weights\n",
        "                                                                output_hidden_states = False #model doesnt return hidden states\n",
        "                                                          )\n",
        "#BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "bert_model.cuda()\n",
        "\n",
        "# Loading RoBERTa base model\n",
        "roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", #RoBERTa base model\n",
        "                                                                    num_labels = 2,  #number of output labels - 0,1 (binary classification)\n",
        "                                                                    output_attentions = False,  #model doesnt return attention weights\n",
        "                                                                    output_hidden_states = False #model doesnt return hidden states\n",
        "                                                                )\n",
        "#RoBERTa tokenizer\n",
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", do_lower_case=True)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "roberta_model.cuda()\n",
        "\n",
        "print(' Base models loaded') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL8GsEMcJSEk"
      },
      "source": [
        "Demonstrating how BERT and RoBERTa tokenizers work on a sample sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJCPEQ2bN0Xf",
        "outputId": "72efe907-17c7-4092-e62e-c5a648330702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  abortion dwayne-bohac State representative Texas republican a mailer Says the Annies List political group supports third-trimester abortions on demand.\n",
            "Tokenized BERT:  ['abortion', 'd', '##way', '##ne', '-', 'bo', '##ha', '##c', 'state', 'representative', 'texas', 'republican', 'a', 'mail', '##er', 'says', 'the', 'annie', '##s', 'list', 'political', 'group', 'supports', 'third', '-', 'trim', '##ester', 'abortion', '##s', 'on', 'demand', '.']\n",
            "Token IDs BERT:  [11324, 1040, 4576, 2638, 1011, 8945, 3270, 2278, 2110, 4387, 3146, 3951, 1037, 5653, 2121, 2758, 1996, 8194, 2015, 2862, 2576, 2177, 6753, 2353, 1011, 12241, 20367, 11324, 2015, 2006, 5157, 1012]\n",
            "Tokenized RoBERT:  ['abortion', 'd', 'wayne', '-', 'b', 'oh', 'ac', 'State', 'representative', 'Texas', 'republican', 'a', 'mail', 'er', 'Says', 'the', 'Ann', 'ies', 'List', 'political', 'group', 'supports', 'third', '-', 'tr', 'imester', 'abortions', 'on', 'demand', '.']\n",
            "Token IDs RoBERTa:  [27275, 385, 20143, 12, 428, 2678, 1043, 331, 4915, 1184, 37958, 10, 7107, 254, 15674, 5, 3921, 918, 9527, 559, 333, 4548, 371, 12, 4328, 38417, 17600, 15, 1077, 4]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', data_train[\"sentence\"][0])\n",
        "\n",
        "# Split the sentence into tokens - BERT\n",
        "print('Tokenized BERT: ', bert_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
        "\n",
        "# Mapping tokens to token IDs - BERT\n",
        "print('Token IDs BERT: ', bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(data_train[\"sentence\"][0])))\n",
        "\n",
        "# Split the sentence into tokens -RoBERTa\n",
        "print('Tokenized RoBERT: ', roberta_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
        "\n",
        "# Mapping tokens to token IDs - RoBERTa\n",
        "print('Token IDs RoBERTa: ', roberta_tokenizer.convert_tokens_to_ids(roberta_tokenizer.tokenize(data_train[\"sentence\"][0])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "B07q6q8JPFBG"
      },
      "outputs": [],
      "source": [
        "#assigning sentences and labels to separate variables\n",
        "sentences = data_train[\"sentence\"].values\n",
        "labels = data_train[\"label\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "10KzxnstQX3S"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "HbpwQQnOdzU9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "agPWz1fH4vi5"
      },
      "outputs": [],
      "source": [
        "# Below function performs tokenization process as required by bert and roberta models, for a given dataset\n",
        "def bert_robert_tokenization(dataset):\n",
        "  sentences = dataset[\"sentence\"].values\n",
        "  labels = dataset[\"label\"].values\n",
        "  max_length = 256\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  bert_input_ids = []\n",
        "  bert_attention_masks = []\n",
        "  roberta_input_ids = []\n",
        "  roberta_attention_masks = []\n",
        "\n",
        "  sentence_ids = []\n",
        "  counter = 0\n",
        "\n",
        "  version = 0\n",
        "\n",
        "  if(version == 0):\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        #encode_plus function will encode the sentences as required by model, including tokenization process and mapping token ids\n",
        "        bert_encoded_dict = bert_tokenizer.encode_plus(\n",
        "                            str(sent),        #sentence              \n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                            max_length = 256,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
        "                            pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                            return_attention_mask = True,   # Create attention mask\n",
        "                            truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        roberta_encoded_dict = roberta_tokenizer.encode_plus(\n",
        "                            str(sent),        #sentence\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                            max_length = 256,        #Since we have seen from our analysis that majority of sentences have length less than 300.   \n",
        "                            pad_to_max_length = True,     # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                            return_attention_mask = True,   # Create attention mask\n",
        "                            truncation = True,   # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "      \n",
        "        # Add the encoded sentence to the list.    \n",
        "        bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
        "        roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
        "        \n",
        "        \n",
        "        # Add attention mask to the list \n",
        "        bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
        "        roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
        "        \n",
        "        \n",
        "        # collecting sentence_ids\n",
        "        sentence_ids.append(counter)\n",
        "        counter  = counter + 1\n",
        "\n",
        "  elif(version ==1):\n",
        "    for sent in sentences:\n",
        "        #encode_plus function will encode the sentences as required by model, including tokenization process and mapping token ids\n",
        "        bert_encoded_dict = bert_tokenizer.encode_plus(\n",
        "                            str(sent),        #sentence              \n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                            max_length = 300,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
        "                            pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                            return_attention_mask = True,   # Create attention mask\n",
        "                            truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        roberta_encoded_dict = roberta_tokenizer.encode_plus(\n",
        "                            str(sent),        #sentence\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                            max_length = 300,        #Since we have seen from our analysis that majority of sentences have length less than 300.   \n",
        "                            pad_to_max_length = True,     # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                            return_attention_mask = True,   # Create attention mask\n",
        "                            truncation = True,   # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        # Add the encoded sentence to the list.    \n",
        "        bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
        "        roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
        "        # Add attention mask to the list \n",
        "        bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
        "        roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
        "        # collecting sentence_ids\n",
        "        sentence_ids.append(counter)\n",
        "        counter  = counter + 1\n",
        "\n",
        "  elif(version == 2):\n",
        "    for sent in sentences:\n",
        "        #encode_plus function will encode the sentences as required by model, including tokenization process and mapping token ids\n",
        "        bert_encoded_dict = bert_tokenizer.encode_plus(\n",
        "                            str(sent),        #sentence              \n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                            max_length = 10,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
        "                            pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                            return_attention_mask = True,   # Create attention mask\n",
        "                            truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        roberta_encoded_dict = roberta_tokenizer.encode_plus(\n",
        "                            str(sent),        #sentence\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                            max_length = 10,        #Since we have seen from our analysis that majority of sentences have length less than 300.   \n",
        "                            pad_to_max_length = True,     # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                            return_attention_mask = True,   # Create attention mask\n",
        "                            truncation = True,   # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        # Add the encoded sentence to the list.    \n",
        "        bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
        "        roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
        "        # Add attention mask to the list \n",
        "        bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
        "        roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
        "        # collecting sentence_ids\n",
        "        sentence_ids.append(counter)\n",
        "        counter  = counter + 1  \n",
        "      \n",
        "  # Convert the lists into tensors.\n",
        "  bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
        "  bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
        "\n",
        "  roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n",
        "  roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "  labels = torch.tensor(labels)\n",
        "  sentence_ids = torch.tensor(sentence_ids)\n",
        "\n",
        "  return {\"Bert\":[bert_input_ids, bert_attention_masks, labels], \"Roberta\":[roberta_input_ids, roberta_attention_masks, labels]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g9y0-vwPFGS",
        "outputId": "172d4155-f778-4f10-8052-99bd361e7bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning:\n",
            "\n",
            "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# function to seed the script globally\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#tokenizing train set\n",
        "token_dict_train = bert_robert_tokenization(data_train)\n",
        "\n",
        "bert_input_ids,bert_attention_masks,labels = token_dict_train[\"Bert\"]\n",
        "roberta_input_ids, roberta_attention_masks, labels = token_dict_train[\"Roberta\"]\n",
        "\n",
        "#tokenizing validation set\n",
        "token_dict_valid = bert_robert_tokenization(data_valid)\n",
        "\n",
        "bert_input_ids_valid,bert_attention_masks_valid,labels_valid = token_dict_valid[\"Bert\"]\n",
        "roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid = token_dict_valid[\"Roberta\"]\n",
        "\n",
        "#tokenizing test set\n",
        "token_dict_test = bert_robert_tokenization(data_test)\n",
        "\n",
        "bert_input_ids_test,bert_attention_masks_test,labels_test = token_dict_test[\"Bert\"]\n",
        "roberta_input_ids_test, roberta_attention_masks_test, labels_test = token_dict_test[\"Roberta\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "lxEtt99NVg6B"
      },
      "outputs": [],
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "bert_train_dataset = TensorDataset( bert_input_ids, bert_attention_masks, labels) \n",
        "roberta_train_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks, labels)\n",
        "\n",
        "# Combine the validation inputs into a TensorDataset.\n",
        "bert_val_dataset = TensorDataset(bert_input_ids_valid,bert_attention_masks_valid,labels_valid)\n",
        "roberta_val_dataset = TensorDataset(roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "62GKzm26WeK2"
      },
      "outputs": [],
      "source": [
        "# Combine the test inputs into a TensorDataset.\n",
        "bert_test_dataset = TensorDataset(bert_input_ids_test,bert_attention_masks_test,labels_test)\n",
        "roberta_test_dataset = TensorDataset(roberta_input_ids_test, roberta_attention_masks_test, labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Q2QhBbROPFI4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training - Loads the data randomly in batches of size 32\n",
        "bert_train_dataloader = DataLoader(\n",
        "            bert_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(bert_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "roberta_train_dataloader = DataLoader(\n",
        "            roberta_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(roberta_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# Create the DataLoaders for our validation - Loads the data in batches of size 32\n",
        "bert_validation_dataloader = DataLoader(\n",
        "            bert_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(bert_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "\n",
        "roberta_validation_dataloader = DataLoader(\n",
        "            roberta_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(roberta_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFQQwKmHPFLi",
        "outputId": "4575a5af-916d-42cb-e5c9-52f9303bf3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning:\n",
            "\n",
            "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# optimizers - AdamW\n",
        "# here, i have used default learning rate and epsilon values for both BERT and RoBERTa\n",
        "bert_optimizer = AdamW(bert_model.parameters(),\n",
        "                  lr = 5e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "\n",
        "roberta_optimizer = AdamW(roberta_model.parameters(),\n",
        "                  lr = 5e-5, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "p-dbnQWqPFOV"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]\n",
        "total_steps = len(bert_train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "roberta_scheduler = get_linear_schedule_with_warmup(roberta_optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "sXWpelrxPFQp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "x4we-u5KIuvI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "NPKi2wBjIuye"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRfZPxcHJOCX",
        "outputId": "559165e2-3038-49f8-988d-72103689ee72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# tell pytorch to use the gpu if available\n",
        "if torch.cuda.is_available():    \n",
        "      \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti2bMAuB2bzS"
      },
      "source": [
        "BERT - Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "1RdHEVGwPFS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL2cv80sj1Gj",
        "outputId": "ace13f67-c554-4358-c9aa-a1424152c34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    320.    Elapsed: 0:00:55.\n",
            "  Batch    80  of    320.    Elapsed: 0:01:48.\n",
            "  Batch   120  of    320.    Elapsed: 0:02:42.\n",
            "  Batch   160  of    320.    Elapsed: 0:03:36.\n",
            "  Batch   200  of    320.    Elapsed: 0:04:29.\n",
            "  Batch   240  of    320.    Elapsed: 0:05:23.\n",
            "  Batch   280  of    320.    Elapsed: 0:06:17.\n",
            "\n",
            "  Average training loss: 0.53\n",
            "  Training epcoh took: 0:07:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:21\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    320.    Elapsed: 0:00:54.\n",
            "  Batch    80  of    320.    Elapsed: 0:01:47.\n",
            "  Batch   120  of    320.    Elapsed: 0:02:41.\n",
            "  Batch   160  of    320.    Elapsed: 0:03:34.\n",
            "  Batch   200  of    320.    Elapsed: 0:04:28.\n",
            "  Batch   240  of    320.    Elapsed: 0:05:22.\n",
            "  Batch   280  of    320.    Elapsed: 0:06:15.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:07:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:21\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "loss_values = []\n",
        "for epoch_i in range(0, epochs):\n",
        "    #Training \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    bert_model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(bert_train_dataloader):\n",
        "      #Report progress after every 40 epochs\n",
        "        if step % 40 == 0 and not step == 0: \n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # print current training batch and elapsed time\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        bert_model.zero_grad()        \n",
        "        \n",
        "        outputs = bert_model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # model returns a tuple, extract loss value from that tuple\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
        "        bert_optimizer.step()\n",
        "        \n",
        "        bert_scheduler.step()\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(bert_train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    #Validation Part\n",
        "\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    # Put the model in evaluation mode    \n",
        "    bert_model.eval()\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in bert_validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "           outputs = bert_model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "yiGhYFoDPFWV",
        "outputId": "157fff4f-82c9-431f-e0eb-60c80b2f44c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"7848879e-0f3d-429d-bad6-89c32ee78113\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7848879e-0f3d-429d-bad6-89c32ee78113\")) {                    Plotly.newPlot(                        \"7848879e-0f3d-429d-bad6-89c32ee78113\",                        [{\"hovertemplate\":\"index=%{x}<br>Loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0,1],\"xaxis\":\"x\",\"y\":[0.5260786504950374,0.2971146530006081],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Training loss of the Model\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7848879e-0f3d-429d-bad6-89c32ee78113');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Plotting the training loss over epochs\n",
        "import plotly.express as px\n",
        "f = pd.DataFrame(loss_values)\n",
        "f.columns=['Loss']\n",
        "fig = px.line(f, x=f.index, y=f.Loss)\n",
        "fig.update_layout(title='Training loss of the Model',\n",
        "                   xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKy4hGqOe6uT"
      },
      "source": [
        "Testing Part\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "iTtJuFyZdH--"
      },
      "outputs": [],
      "source": [
        "bert_prediction_sampler = SequentialSampler(bert_test_dataset)\n",
        "bert_prediction_dataloader = DataLoader(bert_test_dataset, sampler=bert_prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkJsoO6-derz",
        "outputId": "c8cc2145-5785-498f-aa25-240389f46a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 1,267 test sentences...\n"
          ]
        }
      ],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(bert_input_ids_test)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "bert_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SexAvtjMdr76",
        "outputId": "b2ed67ef-dc62-4f8c-853a-4b59263d116a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE.\n"
          ]
        }
      ],
      "source": [
        "# Predict \n",
        "for batch in bert_prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        " \n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = bert_model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSP81-Gzg1YN"
      },
      "source": [
        "Classsification Report and Confusion Matrix for Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQAISJLd023",
        "outputId": "f286ccd3-3ee9-40fc-be4c-4524c89e16db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.72      0.73       833\n",
            "           1       0.48      0.50      0.49       434\n",
            "\n",
            "    accuracy                           0.65      1267\n",
            "   macro avg       0.61      0.61      0.61      1267\n",
            "weighted avg       0.65      0.65      0.65      1267\n",
            "\n",
            "[[601 217]\n",
            " [232 217]]\n"
          ]
        }
      ],
      "source": [
        "predictions_labels = [item for subitem in predictions for item in subitem]\n",
        "\n",
        "predictions_labels = np.argmax(predictions_labels, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print (classification_report(predictions_labels, flat_true_labels))\n",
        "print(confusion_matrix(flat_true_labels, predictions_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5IbjsscfHUA"
      },
      "source": [
        "ROBERTA - Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMFC-RsPF3WN",
        "outputId": "bfeb9c8a-3670-4fff-e5e5-9abda3ff33da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    320.    Elapsed: 0:00:54.\n",
            "  Batch    80  of    320.    Elapsed: 0:01:47.\n",
            "  Batch   120  of    320.    Elapsed: 0:02:41.\n",
            "  Batch   160  of    320.    Elapsed: 0:03:34.\n",
            "  Batch   200  of    320.    Elapsed: 0:04:28.\n",
            "  Batch   240  of    320.    Elapsed: 0:05:21.\n",
            "  Batch   280  of    320.    Elapsed: 0:06:15.\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:07:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    320.    Elapsed: 0:00:54.\n",
            "  Batch    80  of    320.    Elapsed: 0:01:47.\n",
            "  Batch   120  of    320.    Elapsed: 0:02:41.\n",
            "  Batch   160  of    320.    Elapsed: 0:03:35.\n",
            "  Batch   200  of    320.    Elapsed: 0:04:28.\n",
            "  Batch   240  of    320.    Elapsed: 0:05:22.\n",
            "  Batch   280  of    320.    Elapsed: 0:06:16.\n",
            "\n",
            "  Average training loss: 0.65\n",
            "  Training epcoh took: 0:07:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "loss_values = []\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # Training\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    roberta_model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(roberta_train_dataloader):\n",
        "        # Report progress after every 40 epochs\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            #Printing current batch and elapsed time\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(roberta_train_dataloader), elapsed))\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        roberta_model.zero_grad()        \n",
        "        \n",
        "        outputs = roberta_model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # Model returns tuple, extract loss value from that tuple\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n",
        "        roberta_optimizer.step()\n",
        "        \n",
        "        roberta_scheduler.step()\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(roberta_train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # Validation\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    # Put the model in evaluation mode    \n",
        "    roberta_model.eval()\n",
        "     \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in roberta_validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "           \n",
        "            outputs = roberta_model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        \n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "_IY2ObaweJTJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Z99-6YgpF0"
      },
      "source": [
        "Testing Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "sR2Ceh17eQGU"
      },
      "outputs": [],
      "source": [
        "roberta_prediction_sampler = SequentialSampler(roberta_test_dataset)\n",
        "roberta_prediction_dataloader = DataLoader(roberta_test_dataset, sampler=roberta_prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozbBzSaceQGV",
        "outputId": "f665a492-7089-4dfa-fe14-00f3ee3d075c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 1,267 test sentences...\n"
          ]
        }
      ],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(bert_input_ids_test)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "roberta_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqI2kwzfeQGV",
        "outputId": "86110ea8-3b9a-4b4a-8a74-393f4b18b11c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    DONE.\n"
          ]
        }
      ],
      "source": [
        "# Predict \n",
        "for batch in roberta_prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "      \n",
        "      outputs = roberta_model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  \n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzivU_H4g8Sj"
      },
      "source": [
        "Classification report and Confusion Matrix for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "F2AsiB3yeQGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21427fc5-edd8-4e2e-ab24-73c61eee8cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.65      0.78      1267\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.65      1267\n",
            "   macro avg       0.50      0.32      0.39      1267\n",
            "weighted avg       1.00      0.65      0.78      1267\n",
            "\n",
            "[[818   0]\n",
            " [449   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning:\n",
            "\n",
            "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions_labels = [item for subitem in predictions for item in subitem]\n",
        "\n",
        "predictions_labels = np.argmax(predictions_labels, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print (classification_report(predictions_labels, flat_true_labels))\n",
        "print(confusion_matrix(flat_true_labels, predictions_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m---0yKjQfUd"
      },
      "source": [
        "References:\n",
        "https://www.kaggle.com/jaskaransingh/fake-news-classification-bert-roberta\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}